{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f4a3fb1-ceab-46e3-9076-ad88d84655ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best Parameters for xyz_vaccine: {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Best Score for xyz_vaccine: 0.8365598422690445\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best Parameters for seasonal_vaccine: {'criterion': 'entropy', 'max_depth': 18, 'max_features': 'sqrt', 'n_estimators': 300}\n",
      "Best Score for seasonal_vaccine: 0.7825665782337926\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # One hot encode with a new class for missing values\n",
    "    def one_hot_encode_with_missing(df, column, missing_value_class):\n",
    "        df[column].fillna(missing_value_class, inplace=True)\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        encoded = encoder.fit_transform(df[[column]])\n",
    "        columns = [f\"{column}_{cat}\" for cat in encoder.categories_[0]]\n",
    "        df_encoded = pd.DataFrame(encoded, columns=columns, index=df.index)\n",
    "        df = pd.concat([df.drop(columns=[column]), df_encoded], axis=1)\n",
    "        return df\n",
    "\n",
    "    # Fill missing values with 0\n",
    "    def fill_missing_with_zero(df, columns):\n",
    "        for column in columns:\n",
    "            df[column].fillna(0, inplace=True)\n",
    "        return df\n",
    "\n",
    "    # Fill missing values with the most frequent class\n",
    "    def fill_missing_with_most_frequent(df, column):\n",
    "        most_frequent = df[column].mode()[0]\n",
    "        df[column].fillna(most_frequent, inplace=True)\n",
    "        return df\n",
    "\n",
    "    # Columns to preprocess\n",
    "    binary_columns = [\n",
    "        'xyz_concern', 'xyz_knowledge', 'behavioral_antiviral_meds', 'behavioral_avoidance',\n",
    "        'behavioral_face_mask', 'behavioral_wash_hands', 'behavioral_large_gatherings',\n",
    "        'behavioral_outside_home', 'behavioral_touch_face', 'doctor_recc_xyz',\n",
    "        'doctor_recc_seasonal', 'chronic_med_condition', 'child_under_6_months', 'health_worker',\n",
    "        'health_insurance', 'opinion_xyz_vacc_effective', 'opinion_xyz_risk',\n",
    "        'opinion_xyz_sick_from_vacc', 'opinion_seas_vacc_effective', 'opinion_seas_risk',\n",
    "        'opinion_seas_sick_from_vacc'\n",
    "    ]\n",
    "\n",
    "    # Handle 'employment_occupation' and 'employment_industry'\n",
    "    df = one_hot_encode_with_missing(df, 'employment_occupation', 'Missing')\n",
    "    df = one_hot_encode_with_missing(df, 'employment_industry', 'Missing')\n",
    "\n",
    "    # Handle 'household_adults' and 'household_children'\n",
    "    df = fill_missing_with_zero(df, ['household_adults', 'household_children'])\n",
    "\n",
    "    # One hot encode 'hhs_geo_region' and 'census_msa'\n",
    "    df = one_hot_encode_with_missing(df, 'hhs_geo_region', 'Missing')  # Treat missing values as a separate class\n",
    "    df = one_hot_encode_with_missing(df, 'census_msa', 'Missing')  # Treat missing values as a separate class\n",
    "\n",
    "    # Handle 'employment_status'\n",
    "    df['employment_status'].fillna('Unemployed', inplace=True)\n",
    "    df = one_hot_encode_with_missing(df, 'employment_status', 'Unemployed')\n",
    "\n",
    "    # Handle 'rent_or_own'\n",
    "    df = one_hot_encode_with_missing(df, 'rent_or_own', 'Missing')\n",
    "\n",
    "    # Handle 'marital_status'\n",
    "    df['marital_status'].fillna('Not Married', inplace=True)\n",
    "    df = one_hot_encode_with_missing(df, 'marital_status', 'Not Married')\n",
    "\n",
    "    # Handle 'income_poverty'\n",
    "    df['income_poverty'].fillna('<= $75,000, Above Poverty', inplace=True)\n",
    "    df = one_hot_encode_with_missing(df, 'income_poverty', '<= $75,000, Above Poverty')\n",
    "\n",
    "    # One hot encode 'sex', 'race', and 'age_group'\n",
    "    df = one_hot_encode_with_missing(df, 'sex', 'Missing')  # Treat missing values as a separate class\n",
    "    df = one_hot_encode_with_missing(df, 'race', 'Missing')  # Treat missing values as a separate class\n",
    "    df = one_hot_encode_with_missing(df, 'age_group', 'Missing')  # Treat missing values as a separate class\n",
    "\n",
    "    # Handle 'education'\n",
    "    most_frequent_education = df['education'].mode()[0]\n",
    "    df['education'].fillna(most_frequent_education, inplace=True)\n",
    "    df = one_hot_encode_with_missing(df, 'education', most_frequent_education)\n",
    "    df = df.drop(columns=['respondent_id'])\n",
    "\n",
    "    # Handle remaining binary columns\n",
    "    for column in binary_columns:\n",
    "        df = fill_missing_with_most_frequent(df, column)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_and_preprocess_data(features_csv, labels_csv, test_features_csv):\n",
    "    # Load the data\n",
    "    df_features = pd.read_csv(features_csv)\n",
    "    df_labels = pd.read_csv(labels_csv)\n",
    "    df_test_features = pd.read_csv(test_features_csv)\n",
    "\n",
    "    # Preprocess the features\n",
    "    df_features = preprocess_data(df_features)\n",
    "    df_test_features = preprocess_data(df_test_features)\n",
    "\n",
    "    return df_features, df_labels, df_test_features\n",
    "\n",
    "def train_rf_and_predict(features, labels, test_features):\n",
    "    # Split the labels into the two target columns\n",
    "    y_xyz_vaccine = labels['xyz_vaccine']\n",
    "    y_seasonal_vaccine = labels['seasonal_vaccine']\n",
    "\n",
    "    # Define the parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'max_depth': [10, 12,16,18],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    # Train Random Forest for xyz_vaccine\n",
    "    rf_xyz = RandomForestClassifier()\n",
    "    grid_search_xyz = GridSearchCV(rf_xyz, param_grid, refit=True, verbose=3, cv=5, n_jobs=-1)\n",
    "    grid_search_xyz.fit(features, y_xyz_vaccine)\n",
    "    best_model_xyz = grid_search_xyz.best_estimator_\n",
    "\n",
    "    # Print the best parameters and best score for xyz_vaccine\n",
    "    print(\"Best Parameters for xyz_vaccine:\", grid_search_xyz.best_params_)\n",
    "    print(\"Best Score for xyz_vaccine:\", grid_search_xyz.best_score_)\n",
    "\n",
    "    # Train Random Forest for seasonal_vaccine\n",
    "    rf_seasonal = RandomForestClassifier()\n",
    "    grid_search_seasonal = GridSearchCV(rf_seasonal, param_grid, refit=True, verbose=3, cv=5, n_jobs=-1)\n",
    "    grid_search_seasonal.fit(features, y_seasonal_vaccine)\n",
    "    best_model_seasonal = grid_search_seasonal.best_estimator_\n",
    "\n",
    "    # Print the best parameters and best score for seasonal_vaccine\n",
    "    print(\"Best Parameters for seasonal_vaccine:\", grid_search_seasonal.best_params_)\n",
    "    print(\"Best Score for seasonal_vaccine:\", grid_search_seasonal.best_score_)\n",
    "\n",
    "    # Predict probabilities for the test set\n",
    "    predictions_xyz = best_model_xyz.predict_proba(test_features)[:, 1]\n",
    "    predictions_seasonal = best_model_seasonal.predict_proba(test_features)[:, 1]\n",
    "\n",
    "    return predictions_xyz, predictions_seasonal\n",
    "\n",
    "def create_submission_file(test_features_csv, predictions_xyz, predictions_seasonal, output_csv):\n",
    "    # Load the test features to get respondent_ids\n",
    "    df_test_features = pd.read_csv(test_features_csv)\n",
    "    df_submission = pd.DataFrame({\n",
    "        'respondent_id': df_test_features['respondent_id'],\n",
    "        'xyz_vaccine': predictions_xyz,\n",
    "        'seasonal_vaccine': predictions_seasonal\n",
    "    })\n",
    "    df_submission.to_csv(output_csv, index=False)\n",
    "\n",
    "# Example usage:\n",
    "features_csv = 'training_set_features.csv'\n",
    "labels_csv = 'training_set_labels.csv'\n",
    "test_features_csv = 'test_set_features.csv'\n",
    "output_csv = 'output67890.csv'\n",
    "\n",
    "df_features, df_labels, df_test_features = load_and_preprocess_data(features_csv, labels_csv, test_features_csv)\n",
    "predictions_xyz, predictions_seasonal = train_rf_and_predict(df_features, df_labels, df_test_features)\n",
    "create_submission_file(test_features_csv, predictions_xyz, predictions_seasonal, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5feb9fd-92ea-434f-997a-8f755344d4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Best Parameters for xyz_vaccine: {'colsample_bytree': 0.7, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.7}\n",
      "Best Score for xyz_vaccine: 0.8412028800886258\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Best Parameters for seasonal_vaccine: {'colsample_bytree': 0.9, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.7}\n",
      "Best Score for seasonal_vaccine: 0.7883327488356603\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def preprocess_data(df):\n",
    "    def one_hot_encode_with_missing(df, column, missing_value_class):\n",
    "        df[column].fillna(missing_value_class, inplace=True)\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        encoded = encoder.fit_transform(df[[column]])\n",
    "        columns = [f\"{column}_{cat}\".replace(\"[\", \"\").replace(\"]\", \"\").replace(\"<\", \"\") for cat in encoder.categories_[0]]\n",
    "        df_encoded = pd.DataFrame(encoded, columns=columns, index=df.index)\n",
    "        df = pd.concat([df.drop(columns=[column]), df_encoded], axis=1)\n",
    "        return df\n",
    "\n",
    "    def fill_missing_with_zero(df, columns):\n",
    "        for column in columns:\n",
    "            df[column].fillna(0, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def fill_missing_with_most_frequent(df, column):\n",
    "        most_frequent = df[column].mode()[0]\n",
    "        df[column].fillna(most_frequent, inplace=True)\n",
    "        return df\n",
    "\n",
    "    binary_columns = [\n",
    "        'xyz_concern', 'xyz_knowledge', 'behavioral_antiviral_meds', 'behavioral_avoidance',\n",
    "        'behavioral_face_mask', 'behavioral_wash_hands', 'behavioral_large_gatherings',\n",
    "        'behavioral_outside_home', 'behavioral_touch_face', 'doctor_recc_xyz',\n",
    "        'doctor_recc_seasonal', 'chronic_med_condition', 'child_under_6_months', 'health_worker',\n",
    "        'health_insurance', 'opinion_xyz_vacc_effective', 'opinion_xyz_risk',\n",
    "        'opinion_xyz_sick_from_vacc', 'opinion_seas_vacc_effective', 'opinion_seas_risk',\n",
    "        'opinion_seas_sick_from_vacc'\n",
    "    ]\n",
    "\n",
    "    df = one_hot_encode_with_missing(df, 'employment_occupation', 'Missing')\n",
    "    df = one_hot_encode_with_missing(df, 'employment_industry', 'Missing')\n",
    "    df = fill_missing_with_zero(df, ['household_adults', 'household_children'])\n",
    "    df = one_hot_encode_with_missing(df, 'hhs_geo_region', 'Missing')\n",
    "    df = one_hot_encode_with_missing(df, 'census_msa', 'Missing')\n",
    "    df['employment_status'].fillna('Unemployed', inplace=True)\n",
    "    df = one_hot_encode_with_missing(df, 'employment_status', 'Unemployed')\n",
    "    df = one_hot_encode_with_missing(df, 'rent_or_own', 'Missing')\n",
    "    df['marital_status'].fillna('Not Married', inplace=True)\n",
    "    df = one_hot_encode_with_missing(df, 'marital_status', 'Not Married')\n",
    "    df['income_poverty'].fillna('<= $75,000, Above Poverty', inplace=True)\n",
    "    df = one_hot_encode_with_missing(df, 'income_poverty', '<= $75,000, Above Poverty')\n",
    "    df = one_hot_encode_with_missing(df, 'sex', 'Missing')\n",
    "    df = one_hot_encode_with_missing(df, 'race', 'Missing')\n",
    "    df = one_hot_encode_with_missing(df, 'age_group', 'Missing')\n",
    "    most_frequent_education = df['education'].mode()[0]\n",
    "    df['education'].fillna(most_frequent_education, inplace=True)\n",
    "    df = one_hot_encode_with_missing(df, 'education', most_frequent_education)\n",
    "    df = df.drop(columns=['respondent_id'])\n",
    "\n",
    "    for column in binary_columns:\n",
    "        df = fill_missing_with_most_frequent(df, column)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_and_preprocess_data(features_csv, labels_csv, test_features_csv):\n",
    "    df_features = pd.read_csv(features_csv)\n",
    "    df_labels = pd.read_csv(labels_csv)\n",
    "    df_test_features = pd.read_csv(test_features_csv)\n",
    "\n",
    "    df_features = preprocess_data(df_features)\n",
    "    df_test_features = preprocess_data(df_test_features)\n",
    "\n",
    "    return df_features, df_labels, df_test_features\n",
    "\n",
    "def train_xgb_and_predict(features, labels, test_features):\n",
    "    y_xyz_vaccine = labels['xyz_vaccine']\n",
    "    y_seasonal_vaccine = labels['seasonal_vaccine']\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.7, 0.8, 0.9],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "        'gamma': [0, 0.1, 0.2]\n",
    "    }\n",
    "\n",
    "    xgb_xyz = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    grid_search_xyz = GridSearchCV(xgb_xyz, param_grid, refit=True, verbose=3, cv=5, n_jobs=-1)\n",
    "    grid_search_xyz.fit(features, y_xyz_vaccine)\n",
    "    best_model_xyz = grid_search_xyz.best_estimator_\n",
    "\n",
    "    print(\"Best Parameters for xyz_vaccine:\", grid_search_xyz.best_params_)\n",
    "    print(\"Best Score for xyz_vaccine:\", grid_search_xyz.best_score_)\n",
    "\n",
    "    xgb_seasonal = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    grid_search_seasonal = GridSearchCV(xgb_seasonal, param_grid, refit=True, verbose=3, cv=5, n_jobs=-1)\n",
    "    grid_search_seasonal.fit(features, y_seasonal_vaccine)\n",
    "    best_model_seasonal = grid_search_seasonal.best_estimator_\n",
    "\n",
    "    print(\"Best Parameters for seasonal_vaccine:\", grid_search_seasonal.best_params_)\n",
    "    print(\"Best Score for seasonal_vaccine:\", grid_search_seasonal.best_score_)\n",
    "\n",
    "    predictions_xyz = best_model_xyz.predict_proba(test_features)[:, 1]\n",
    "    predictions_seasonal = best_model_seasonal.predict_proba(test_features)[:, 1]\n",
    "\n",
    "    return predictions_xyz, predictions_seasonal\n",
    "\n",
    "def create_submission_file(test_features_csv, predictions_xyz, predictions_seasonal, output_csv):\n",
    "    df_test_features = pd.read_csv(test_features_csv)\n",
    "    df_submission = pd.DataFrame({\n",
    "        'respondent_id': df_test_features['respondent_id'],\n",
    "        'xyz_vaccine': predictions_xyz,\n",
    "        'seasonal_vaccine': predictions_seasonal\n",
    "    })\n",
    "    df_submission.to_csv(output_csv, index=False)\n",
    "\n",
    "# Example usage:\n",
    "features_csv = 'training_set_features.csv'\n",
    "labels_csv = 'training_set_labels.csv'\n",
    "test_features_csv = 'test_set_features.csv'\n",
    "output_csv = 'output12345.csv'\n",
    "\n",
    "df_features, df_labels, df_test_features = load_and_preprocess_data(features_csv, labels_csv, test_features_csv)\n",
    "predictions_xyz, predictions_seasonal = train_xgb_and_predict(df_features, df_labels, df_test_features)\n",
    "create_submission_file(test_features_csv, predictions_xyz, predictions_seasonal, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc50ebdb-60fd-4ec4-86c0-2f66595ec8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xyz_concern</th>\n",
       "      <th>xyz_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_xyz</th>\n",
       "      <th>...</th>\n",
       "      <th>race_White</th>\n",
       "      <th>age_group_18 - 34 Years</th>\n",
       "      <th>age_group_35 - 44 Years</th>\n",
       "      <th>age_group_45 - 54 Years</th>\n",
       "      <th>age_group_55 - 64 Years</th>\n",
       "      <th>age_group_65+ Years</th>\n",
       "      <th>education_12 Years</th>\n",
       "      <th>education_ 12 Years</th>\n",
       "      <th>education_College Graduate</th>\n",
       "      <th>education_Some College</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17894</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17896</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17897</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17898</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17899 rows Ã— 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       xyz_concern  xyz_knowledge  behavioral_antiviral_meds  \\\n",
       "0              1.0            0.0                        0.0   \n",
       "1              3.0            2.0                        0.0   \n",
       "2              1.0            1.0                        0.0   \n",
       "3              1.0            1.0                        0.0   \n",
       "4              2.0            1.0                        0.0   \n",
       "...            ...            ...                        ...   \n",
       "17894          2.0            2.0                        0.0   \n",
       "17895          1.0            1.0                        0.0   \n",
       "17896          2.0            2.0                        0.0   \n",
       "17897          1.0            1.0                        0.0   \n",
       "17898          1.0            1.0                        0.0   \n",
       "\n",
       "       behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "0                       0.0                   0.0                    0.0   \n",
       "1                       1.0                   0.0                    1.0   \n",
       "2                       1.0                   0.0                    0.0   \n",
       "3                       1.0                   0.0                    1.0   \n",
       "4                       1.0                   0.0                    1.0   \n",
       "...                     ...                   ...                    ...   \n",
       "17894                   1.0                   0.0                    1.0   \n",
       "17895                   1.0                   0.0                    1.0   \n",
       "17896                   0.0                   0.0                    0.0   \n",
       "17897                   1.0                   0.0                    1.0   \n",
       "17898                   1.0                   0.0                    1.0   \n",
       "\n",
       "       behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "0                              0.0                      1.0   \n",
       "1                              0.0                      1.0   \n",
       "2                              0.0                      0.0   \n",
       "3                              1.0                      0.0   \n",
       "4                              1.0                      0.0   \n",
       "...                            ...                      ...   \n",
       "17894                          0.0                      0.0   \n",
       "17895                          1.0                      1.0   \n",
       "17896                          0.0                      0.0   \n",
       "17897                          0.0                      0.0   \n",
       "17898                          0.0                      0.0   \n",
       "\n",
       "       behavioral_touch_face  doctor_recc_xyz  ...  race_White  \\\n",
       "0                        1.0              0.0  ...         1.0   \n",
       "1                        1.0              0.0  ...         1.0   \n",
       "2                        0.0              0.0  ...         1.0   \n",
       "3                        0.0              0.0  ...         1.0   \n",
       "4                        1.0              0.0  ...         1.0   \n",
       "...                      ...              ...  ...         ...   \n",
       "17894                    0.0              0.0  ...         1.0   \n",
       "17895                    1.0              0.0  ...         0.0   \n",
       "17896                    0.0              0.0  ...         1.0   \n",
       "17897                    1.0              0.0  ...         1.0   \n",
       "17898                    1.0              0.0  ...         1.0   \n",
       "\n",
       "       age_group_18 - 34 Years  age_group_35 - 44 Years  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      1.0   \n",
       "2                          1.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "17894                      0.0                      0.0   \n",
       "17895                      0.0                      1.0   \n",
       "17896                      0.0                      0.0   \n",
       "17897                      0.0                      0.0   \n",
       "17898                      0.0                      0.0   \n",
       "\n",
       "       age_group_45 - 54 Years  age_group_55 - 64 Years  age_group_65+ Years  \\\n",
       "0                          0.0                      1.0                  0.0   \n",
       "1                          0.0                      0.0                  0.0   \n",
       "2                          0.0                      0.0                  0.0   \n",
       "3                          0.0                      0.0                  1.0   \n",
       "4                          1.0                      0.0                  0.0   \n",
       "...                        ...                      ...                  ...   \n",
       "17894                      0.0                      0.0                  1.0   \n",
       "17895                      0.0                      0.0                  0.0   \n",
       "17896                      1.0                      0.0                  0.0   \n",
       "17897                      1.0                      0.0                  0.0   \n",
       "17898                      0.0                      0.0                  1.0   \n",
       "\n",
       "       education_12 Years  education_ 12 Years  education_College Graduate  \\\n",
       "0                     0.0                  1.0                         0.0   \n",
       "1                     1.0                  0.0                         0.0   \n",
       "2                     0.0                  0.0                         1.0   \n",
       "3                     1.0                  0.0                         0.0   \n",
       "4                     0.0                  0.0                         0.0   \n",
       "...                   ...                  ...                         ...   \n",
       "17894                 0.0                  0.0                         0.0   \n",
       "17895                 0.0                  1.0                         0.0   \n",
       "17896                 0.0                  0.0                         1.0   \n",
       "17897                 0.0                  0.0                         1.0   \n",
       "17898                 1.0                  0.0                         0.0   \n",
       "\n",
       "       education_Some College  \n",
       "0                         0.0  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.0  \n",
       "4                         1.0  \n",
       "...                       ...  \n",
       "17894                     1.0  \n",
       "17895                     0.0  \n",
       "17896                     0.0  \n",
       "17897                     0.0  \n",
       "17898                     0.0  \n",
       "\n",
       "[17899 rows x 108 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head(17899)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d371246a-b139-4ba9-aa6d-cb4887041efb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
